# Intelligent Complaint Analysis for Financial Services (RAG Chatbot)

This project is part of the **10 Academy KAIM 5 - Week 6** challenge. It aims to build a **RAG-powered internal chatbot** that allows teams at **CrediTrust Financial** to analyze thousands of customer complaints efficiently using **LLMs + semantic search**.

---

## ğŸ§  Business Context

**CrediTrust** receives thousands of monthly complaints about its financial products (credit cards, loans, BNPL, etc.). Product managers and compliance teams currently read complaints manually â€” costing time and losing insights.

We built a **Retrieval-Augmented Generation (RAG)** system to:
- Let users ask questions in natural language
- Retrieve relevant complaint narratives from a vector DB
- Generate grounded, actionable answers using a language model

---

## ğŸš€ Final Deliverables

- âœ… A cleaned & filtered CFPB complaints dataset
- âœ… Text embeddings chunked and stored in FAISS vector DB
- âœ… RAG core logic with evaluation
- âœ… Streamlit UI for interactive chat
- âœ… ğŸ“„ Final blog-style report

---

## ğŸ§° Tech Stack

| Component      | Tool/Library                        |
|----------------|-------------------------------------|
| Language Model | `sentence-transformers` (MiniLM)    |
| Vector DB      | `FAISS`                             |
| LLM Framework  | `LangChain`, `Transformers`         |
| UI             | `Streamlit` or `Gradio`             |
| Data           | CFPB Complaints Dataset             |
| Hardware       | GPU-enabled via PyTorch             |

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ filtered_complaints.csv        # Cleaned dataset
â”‚
â”œâ”€â”€ vector_store/
â”‚   â”œâ”€â”€ faiss_index.bin               # FAISS vector index
â”‚   â””â”€â”€ metadata.pkl                  # Corresponding chunk metadata
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ task_1_eda_and_preprocessing.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ build_vector_store.py         # Task 2 script
â”‚   â”œâ”€â”€ rag_pipeline.py               # Task 3 logic
â”‚   â””â”€â”€ app.py                        # Task 4: Chat UI
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
````

---

## âœ… Task 1: EDA & Preprocessing

### ğŸ”§ Actions:

* Loaded CFPB complaints CSV
* Filtered for 5 relevant products:

  * Credit card, Personal loan, Buy Now Pay Later (BNPL), Savings account, Money transfers
* Removed empty complaint narratives
* Cleaned text (lowercase, removed boilerplate)

### ğŸ“ Output:

* `data/filtered_complaints.csv`

---

## âœ… Task 2: Chunking, Embedding & Indexing

### ğŸ”§ Actions:

* Used `LangChain.RecursiveCharacterTextSplitter` with:

  * `chunk_size = 300`, `chunk_overlap = 50`
* Generated embeddings using:

  * `sentence-transformers/all-MiniLM-L6-v2` (on GPU)
* Stored embeddings + metadata using FAISS

### ğŸ“ Output:

* `vector_store/faiss_index.bin`
* `vector_store/metadata.pkl`

---

## âœ… Task 3: RAG Pipeline + Evaluation

### ğŸ”§ Actions:

* Implemented RAG logic in `rag_pipeline.py`:

  * Embed query â†’ Search FAISS â†’ Prompt LLM with top-k chunks
* Prompt format:

  ```
  You are a financial analyst assistant for CrediTrust.
  Use the following context to answer:
  Context: {context}
  Question: {question}
  Answer:
  ```
* Evaluated the system using 5â€“10 sample queries

  * Metrics: answer relevance, groundedness, clarity

### ğŸ“ Output:

* Evaluation table (Markdown)
* Analysis & tuning notes in final report

---

## âœ… Task 4: Interactive Chat Interface

### ğŸ”§ Actions:

* Built a Streamlit (or Gradio) UI
* User can:

  * Type a question
  * See LLM-generated answer
  * View sources (retrieved chunks)
  * Optional: Streaming responses

### ğŸ“ Output:

* `src/app.py`
* Screenshots in final report

---

## ğŸ§ª How to Run

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Launch the chat app

```bash
streamlit run src/app.py
```

---
